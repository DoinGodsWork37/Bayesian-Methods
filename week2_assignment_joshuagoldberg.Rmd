---
title: "Week 2 Assignment"
author: "Joshua Goldberg"
date: "`r format(Sys.time(), '%B, %d %Y')`"
always_allow_html: yes
output:
  github_document: 
  pdf_document: default
editor_options: 
  chunk_output_type: inline
---

```{r Global-options, include=FALSE}
knitr::opts_chunk$set(fig.width=6, fig.height=4, fig.path='Figs/',
                      warning=FALSE, message=FALSE, cache=TRUE)
```

```{r Preamble, echo=FALSE}
# Enter package in p_load()
# If package is not installed, p_load() will install and load the package
if(!"pacman" %in% rownames(installed.packages())) {
  install.packages("pacman")
  }
pacman::p_load(tidyverse, ggthemes, here)

# Set default ggplot theme to tufte
theme_set(ggthemes::theme_tufte())
```

```{r Copy-files, echo=FALSE, eval=FALSE}
# Enter files to load to project directory in from = "~/Downloads/your_file_name_here"
file.copy(from = "~/Downloads/", to = here::here(), 
          overwrite = TRUE, recursive = FALSE, 
          copy.mode = TRUE)
```

**This projects helps understanding how Bayes theorem is used in data analysis**

# 1 Posterior Distribuion for Binomial Model
Repeat calculations of Section 5 of the workshop:

Follow the steps of obtaining posterior distribution by Monte Carlo.

Define likelihood function for binomial distribution.
```{r}
likeli <- function(par, data) {
  sdata <- sum(data)
  ldata <- length(data)
  return(par ^ sdata * (1 - par) ^ (ldata - sdata))
}
```

Define values of parameter $\theta$ and prior distribution.
```{r}
Theta = seq(.00001 , 1 - .00001 , length = 1001) # fine grid for Theta.
pTheta = rep(1, length(Theta))      # Uniform (horizontal) shape for pTheta.
pTheta = pTheta / sum(pTheta)        # Make pTheta sum to 1.0
plot(Theta, pTheta)
```

Create data of length 5 generated by the model with parameter 0.84.
```{r}
set.seed(5)
(Data <- rbinom(5, size = 1, prob = .84))
```

Create sample of $\theta$ generated from the prior distribution.
```{r}
set.seed(15)
priorInd <- sample(1:length(Theta), 500, replace = T)
priorSample <- cbind(Theta = Theta[priorInd], Prob = pTheta[priorInd])
priorSample <- rbind(priorSample,
                     c(head(Theta, 1), head(pTheta, 1)),
                     c(tail(Theta, 1), tail(pTheta, 1)))
```

Calculate likelihood for each simulated $\theta$ and the data.
```{r}
likelihoodVector <- sapply(priorSample[, "Theta"], function(z) likeli(z, Data))
plot(priorSample[, "Theta"], likelihoodVector)
```

Calculate posterior distribution.

* Calculate vector of numerators of the Bayes theorem

* Normalize it

* Create function for linear interpolation of vector of numerator

```{r}
postVector <- priorSample[, "Prob"] * likelihoodVector
postVector <- postVector / sum(postVector)
plot(priorSample[, "Theta"], postVector)

postDistr <- approxfun(priorSample[, "Theta"], postVector, method = "linear")
plot(priorSample[, "Theta"], postVector)
lines(Theta, postDistr(Theta), col = "red", lwd = 2)
```

```{r}
length(postDistr(Theta))
postDistr1 <- postDistr(Theta)
```

Calculate mode, mean and variance of the posterior distribution.
```{r}
(mode1 <- Theta[which.max(postDistr(Theta))])
(mean1 <- Theta %*% postDistr(Theta) / sum(postDistr(Theta)))
(var1 <- ((Theta - mean1)^2) %*% postDistr(Theta) / sum(postDistr(Theta)))

```

Replace prior distribution with the posterior distribution and generate new data.
```{r}
set.seed(25)
pTheta <- postDistr(Theta) / sum(postDistr(Theta))
(Data <- rbinom(5, size = 1, prob = .84))
```

Repeat the steps of estimation.
```{r}
set.seed(35)
priorInd <- sample(1:length(Theta), 500, replace = T)
priorSample <- cbind(Theta = Theta[priorInd], Prob = pTheta[priorInd])
priorSample <- rbind(priorSample,
                     c(head(Theta, 1), head(pTheta, 1)),
                     c(tail(Theta, 1), tail(pTheta, 1)))

likelihoodVector <- sapply(priorSample[, "Theta"], function(z) likeli(z, Data))
plot(priorSample[, "Theta"], likelihoodVector)
```

```{r}
postVector <- priorSample[, "Prob"] * likelihoodVector
postVector <- postVector / sum(postVector)
plot(priorSample[, "Theta"], postVector)

postDistr <-
  approxfun(priorSample[, "Theta"], postVector, method = "linear")
plot(priorSample[, "Theta"], postVector)
lines(Theta, postDistr(Theta), col = "red", lwd = 2)
```

```{r}
postDistr2 <- postDistr(Theta)
```

Calculate mode, mean and variance of the new posterior distribution.
```{r}
(mode2 <- Theta[which.max(postDistr(Theta))])
(mean2 <- Theta %*% postDistr(Theta) / sum(postDistr(Theta)))
(var2 <- ((Theta - mean2)^2) %*% postDistr(Theta) / sum(postDistr(Theta)))
```

Compare the two posteriors.
```{r}
matplot(
  Theta,
  cbind(postDistr1, postDistr2),
  type = "l",
  lty = 1,
  ylab = "Posterior",
  lwd = 2
)
legend(
  "topleft",
  legend = c("First Sample", "Second Sample"),
  lty = 1,
  col = c("black", "red"),
  lwd = 2
)
```

## 1.1 Find posterior probability for binomial model with uniform prior and data. Use `set.seed(81)` for simulation of $\theta$.

```{r}
set.seed(81)
(data1 <- rbinom(10, 1, .71))
```

