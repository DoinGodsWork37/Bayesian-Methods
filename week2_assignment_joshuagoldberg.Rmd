---
title: "Week 2 Assignment"
author: "Joshua Goldberg"
date: "`r format(Sys.time(), '%B, %d %Y')`"
output:
  html_document:
    df_print: paged
  github_document: null
  pdf_document: default
editor_options:
  chunk_output_type: inline
always_allow_html: yes
---

```{r Global-options, include=FALSE}
knitr::opts_chunk$set(fig.width=6, fig.height=4, fig.path='Figs/',
                      warning=FALSE, message=FALSE, cache=TRUE)
```

```{r Preamble, echo=FALSE}
# Enter package in p_load()
# If package is not installed, p_load() will install and load the package
if(!"pacman" %in% rownames(installed.packages())) {
  install.packages("pacman")
  }
pacman::p_load(tidyverse, ggthemes, here)

# Set default ggplot theme to tufte
theme_set(ggthemes::theme_tufte())
```

```{r Copy-files, echo=FALSE, eval=FALSE}
# Enter files to load to project directory in from = "~/Downloads/your_file_name_here"
file.copy(from = "~/Downloads/", to = here::here(), 
          overwrite = TRUE, recursive = FALSE, 
          copy.mode = TRUE)
```

**This projects helps understanding how Bayes theorem is used in data analysis**

# 1 Posterior Distribuion for Binomial Model
Repeat calculations of Section 5 of the workshop:

Follow the steps of obtaining posterior distribution by Monte Carlo.

Define likelihood function for binomial distribution.
```{r}
likeli <- function(par, data) {
  sdata <- sum(data)
  ldata <- length(data)
  return(par ^ sdata * (1 - par) ^ (ldata - sdata))
}
```

Define values of parameter $\theta$ and prior distribution.
```{r}
Theta = seq(.00001 , 1 - .00001 , length = 1001) # fine grid for Theta.
pTheta = rep(1, length(Theta))      # Uniform (horizontal) shape for pTheta.
pTheta = pTheta / sum(pTheta)        # Make pTheta sum to 1.0
plot(Theta, pTheta)
```

## 1.1 Find posterior probability for binomial model with uniform prior and data. Use `set.seed(81)` for simulation of $\theta$.
```{r}
# set.seed(5)
# (Data <- rbinom(5, size = 1, prob = .84))
set.seed(81)
(data1 <- rbinom(10, 1, .71))
```

Create sample of $\theta$ generated from the prior distribution.
```{r}
set.seed(15)
priorInd <- sample(1:length(Theta), 500, replace = T)
priorSample <- cbind(Theta = Theta[priorInd], Prob = pTheta[priorInd])
priorSample <- rbind(priorSample,
                     c(head(Theta, 1), head(pTheta, 1)),
                     c(tail(Theta, 1), tail(pTheta, 1)))
```

Calculate likelihood for each simulated $\theta$ and the data.
```{r}
likelihoodVector <- sapply(priorSample[, "Theta"], function(z) likeli(z, data1))
plot(priorSample[, "Theta"], likelihoodVector)
```

Calculate posterior distribution.

* Calculate vector of numerators of the Bayes theorem

* Normalize it

* Create function for linear interpolation of vector of numerator

```{r}
postVector <- priorSample[, "Prob"] * likelihoodVector
postVector <- postVector / sum(postVector)
plot(priorSample[, "Theta"], postVector)

postDistr <- approxfun(priorSample[, "Theta"], postVector, method = "linear")
plot(priorSample[, "Theta"], postVector)
lines(Theta, postDistr(Theta), col = "red", lwd = 2)
```

```{r}
length(postDistr(Theta))
postDistr1 <- postDistr(Theta)
```

Calculate mode, mean and variance of the posterior distribution.
```{r}
(mode1 <- Theta[which.max(postDistr(Theta))])
(mean1 <- Theta %*% postDistr(Theta) / sum(postDistr(Theta)))
(var1 <- ((Theta - mean1)^2) %*% postDistr(Theta) / sum(postDistr(Theta)))
```

## 1.2 Add more data and recalculate posterior distribution. Use the `set.seed(97)` for second simulation of $\theta$.

```{r}
set.seed(97)
pTheta <- postDistr(Theta) / sum(postDistr(Theta))
(data2 <- rbinom(10, 1, .71))
```

Repeat the steps of estimation.
```{r}
set.seed(35)
priorInd <- sample(1:length(Theta), 500, replace = T)
priorSample <- cbind(Theta = Theta[priorInd], Prob = pTheta[priorInd])
priorSample <- rbind(priorSample,
                     c(head(Theta, 1), head(pTheta, 1)),
                     c(tail(Theta, 1), tail(pTheta, 1)))

likelihoodVector <- sapply(priorSample[, "Theta"], function(z) likeli(z, data2))
plot(priorSample[, "Theta"], likelihoodVector)
```

```{r}
postVector <- priorSample[, "Prob"] * likelihoodVector
postVector <- postVector / sum(postVector)
plot(priorSample[, "Theta"], postVector)

postDistr <-
  approxfun(priorSample[, "Theta"], postVector, method = "linear")
plot(priorSample[, "Theta"], postVector)
lines(Theta, postDistr(Theta), col = "red", lwd = 2)
```

```{r}
postDistr2 <- postDistr(Theta)
```

Calculate mode, mean and variance of the new posterior distribution.
```{r}
(mode2 <- Theta[which.max(postDistr(Theta))])
(mean2 <- Theta %*% postDistr(Theta) / sum(postDistr(Theta)))
(var2 <- ((Theta - mean2)^2) %*% postDistr(Theta) / sum(postDistr(Theta)))
```

Compare the two posteriors.
```{r}
matplot(
  Theta,
  cbind(postDistr1, postDistr2),
  type = "l",
  lty = 1,
  ylab = "Posterior",
  lwd = 2
)
legend(
  "topleft",
  legend = c("First Sample", "Second Sample"),
  lty = 1,
  col = c("black", "red"),
  lwd = 2
)
```

### 1.3 Repeat steps 1. and 2. using data in reverse order: first use `data2`, then add `data1`.

Create sample of $\theta$ generated from the prior distribution.
```{r}
set.seed(15)
priorInd <- sample(1:length(Theta), 500, replace = T)
priorSample <- cbind(Theta = Theta[priorInd], Prob = pTheta[priorInd])
priorSample <- rbind(priorSample,
                     c(head(Theta, 1), head(pTheta, 1)),
                     c(tail(Theta, 1), tail(pTheta, 1)))
```

Calculate likelihood for each simulated $\theta$ and the data.
```{r}
likelihoodVector <- sapply(priorSample[, "Theta"], function(z) likeli(z, data2))
plot(priorSample[, "Theta"], likelihoodVector)
```

Calculate posterior distribution.

* Calculate vector of numerators of the Bayes theorem

* Normalize it

* Create function for linear interpolation of vector of numerator

```{r}
postVector <- priorSample[, "Prob"] * likelihoodVector
postVector <- postVector / sum(postVector)
plot(priorSample[, "Theta"], postVector)

postDistr <- approxfun(priorSample[, "Theta"], postVector, method = "linear")
plot(priorSample[, "Theta"], postVector)
lines(Theta, postDistr(Theta), col = "red", lwd = 2)
```

```{r}
length(postDistr(Theta))
postDistr3 <- postDistr(Theta)
```

Calculate mode, mean and variance of the posterior distribution.
```{r}
(mode3 <- Theta[which.max(postDistr(Theta))])
(mean3 <- Theta %*% postDistr(Theta) / sum(postDistr(Theta)))
(var3 <- ((Theta - mean3)^2) %*% postDistr(Theta) / sum(postDistr(Theta)))
```

Repeat the steps of estimation.
```{r}
set.seed(35)
priorInd <- sample(1:length(Theta), 500, replace = T)
priorSample <- cbind(Theta = Theta[priorInd], Prob = pTheta[priorInd])
priorSample <- rbind(priorSample,
                     c(head(Theta, 1), head(pTheta, 1)),
                     c(tail(Theta, 1), tail(pTheta, 1)))

likelihoodVector <- sapply(priorSample[, "Theta"], function(z) likeli(z, data1))
plot(priorSample[, "Theta"], likelihoodVector)
```

```{r}
postVector <- priorSample[, "Prob"] * likelihoodVector
postVector <- postVector / sum(postVector)
plot(priorSample[, "Theta"], postVector)

postDistr <-
  approxfun(priorSample[, "Theta"], postVector, method = "linear")
plot(priorSample[, "Theta"], postVector)
lines(Theta, postDistr(Theta), col = "red", lwd = 2)
```

```{r}
postDistr4 <- postDistr(Theta)
```

Calculate mode, mean and variance of the new posterior distribution.
```{r}
(mode4 <- Theta[which.max(postDistr(Theta))])
(mean4 <- Theta %*% postDistr(Theta) / sum(postDistr(Theta)))
(var4 <- ((Theta - mean4)^2) %*% postDistr(Theta) / sum(postDistr(Theta)))
```

Compare the two posteriors.
```{r}
data.frame(postDistr1, postDistr2, postDistr3, postDistr4, Theta) %>%
  gather(key = postDistr, value = value, -5) %>% 
  ggplot(aes(Theta, value, color = postDistr)) +
  geom_line() +
  labs(title = "Comparing Posterior Distributions",
       x = "Theta",
       y = "Posterior") +
  ggthemes::theme_tufte()
```

Compare mode, mean and variance of the updated posterior distributions. Order appears to not have a material affect on the final posterior.
```{r, echo=1}
(result <- data.frame(postDistr = c(1, 2, 3, 4),
          mode = rbind(mode1, mode2, mode3, mode4),
          mean = rbind(mean1, mean2, mean3, mean4),
          var = rbind(var1, var2, var3, var4)) %>% 
  as_tibble())

row.names(result) <- NULL
```


